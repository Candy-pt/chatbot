import requests
from bs4 import BeautifulSoup
import time

OLLAMA_API_URL = "http://localhost:11434"

def query_ollama_model(prompt):
    headers = {
        "Content-Type": "application/json"
    }
    data = {
        "model": "llama3.2:1b",
        "prompt": prompt,
        "stream": False
    }
    response = requests.post(f"{OLLAMA_API_URL}/api/generate", json=data, headers=headers)
    return response.json()

def custom_google_search(query, num_results=3):
    try:
        # Format URL t√¨m ki·∫øm Google
        search_url = f"https://www.google.com/search?q={query}&lr=lang_vi&num={num_results}"
        
        # Headers ƒë·ªÉ gi·∫£ l·∫≠p tr√¨nh duy·ªát
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # G·ª≠i request
        response = requests.get(search_url, headers=headers)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # T√¨m c√°c k·∫øt qu·∫£
        search_results = []
        for result in soup.find_all('div', class_='g'):
            link = result.find('a')
            title = result.find('h3')
            snippet = result.find('div', class_='VwiC3b')
            
            if link and title and snippet:
                search_results.append({
                    'url': link['href'],
                    'title': title.text,
                    'snippet': snippet.text
                })
            if len(search_results) >= num_results:
                break
            time.sleep(1)
                
        return search_results
    except Exception as e:
        return f"L·ªói khi t√¨m ki·∫øm: {str(e)}"

def analyze_query_type(query):
    # Danh s√°ch t·ª´ kh√≥a cho c√¢u h·ªèi c·∫ßn tham kh·∫£o
    knowledge_keywords = [
        'l√† g√¨', 'ƒë·ªãnh nghƒ©a', 'gi·∫£i th√≠ch', 'th·∫ø n√†o',
        'c√°ch', 'l√†m sao', 'v√≠ d·ª•', 'tr√¨nh b√†y', 't·ªïng h·ª£p',
        'so s√°nh', 'kh√°c nhau', 't·∫°i sao', 'v√¨ sao',
        'explain', 'l√¢u', 'h√¨nh th√†nh', 
        'ph√°t tri·ªÉn','t·ªïng quan','t·ªïng qu√°t'
    ]
    
    # Danh s√°ch t·ª´ kh√≥a cho c√¢u h·ªèi ƒë∆°n gi·∫£n
    simple_keywords = [
        'ch√†o', 'hi', 'hello', 'bye', 't·∫°m bi·ªát',
        'kh·ªèe kh√¥ng', 'b·∫°n t√™n g√¨','th·∫ø n√†o','v·∫•n ƒë·ªÅ'
    ]
    
    query = query.lower()
    
    # Ki·ªÉm tra n·∫øu l√† c√¢u h·ªèi c·∫ßn tham kh·∫£o
    for keyword in knowledge_keywords:
        if keyword in query:
            return "need_reference"
            
    # Ki·ªÉm tra n·∫øu l√† c√¢u h·ªèi ƒë∆°n gi·∫£n
    for keyword in simple_keywords:
        if keyword in query:
            return "simple_chat"
            
    # M·∫∑c ƒë·ªãnh c·∫ßn tham kh·∫£o n·∫øu kh√¥ng r∆°i v√†o c√°c tr∆∞·ªùng h·ª£p tr√™n
    return "need_reference"


def process_query(user_input):
    query_type = analyze_query_type(user_input)
    
    # L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ model
    model_response = query_ollama_model(user_input)
    response = "ü§ñ \n"
    response += f"{model_response['response']}\n\n"
    
    # Ch·ªâ th√™m tham kh·∫£o n·∫øu c·∫ßn
    if query_type == "need_reference":
        search_results = custom_google_search(user_input)
        response += "üìö Ngu·ªìn tham kh·∫£o:\n"
        if isinstance(search_results, list):
            for i, result in enumerate(search_results, 1):
                response += f"\n{i}. <a href='{result['url']}' target='_blank'>{result['title']}</a>\n"

    return {"response": response}